{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCSM Testing - Version 0.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os, sys\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "# Settings:\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 32\n",
    "DIM = 300\n",
    "NUM_WORKERS = 0\n",
    "USE_TRAIN_AUGMENTATION = False\n",
    "USE_TEST_AUGMENTATION = False\n",
    "USE_LAZY_IMAGE_LOADING = True # Saves memory but is slower (image is read from harddrive on each request by dataloader instead of RAM)\n",
    "\n",
    "# Source folders\n",
    "googleFolderPath = \"C:\\\\food-training-images-database\\\\data\\\\food images\\\\google\" # 0\n",
    "sourceImageFolder = \"C:\\\\ExtremePictureFinder\\\\Processed\" # 1\n",
    "\n",
    "sourceToUse = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "To prepare for learning we first select the most recent subfolder from the google folder which coresponds to the most recent run of the image scraper tool so make sure the google folder contains at least one subfolder with image data in it. Next, the train and test images are loaded for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if sourceToUse == 0:\n",
    "    if not os.path.exists(googleFolderPath):\n",
    "        raise ValueError('The specified google folder path does not exist.')\n",
    "\n",
    "    # Get the subfolders of the google folder\n",
    "    subfolders = [name for name in os.listdir(googleFolderPath) if os.path.isdir(os.path.join(googleFolderPath, name))]\n",
    "    subfoldersDates = []\n",
    "    for i in range(0, len(subfolders)):\n",
    "        subfoldersDates.append(dt.datetime.strptime(subfolders[i], \"%d%m%y_%H%M\"))\n",
    "\n",
    "    if len(subfolders) <= 0 or len(subfoldersDates) <= 0:\n",
    "        raise ValueError('No image data found, run the image scaper tool.')\n",
    "\n",
    "    # Sort the subfolders by date and select the most recent\n",
    "    subfoldersDates.sort()\n",
    "    databasePath = googleFolderPath + \"\\\\\" + subfoldersDates[-1].strftime(\"%d%m%y_%H%M\") + \"\\\\DL\"\n",
    "    # Just use this one please:\n",
    "    databasePath = googleFolderPath + \"\\\\\" + \"291018_1724\\\\DL\"\n",
    "    trainSetCSV = pd.read_csv(databasePath + \"\\\\train_clean.csv\")\n",
    "    testSetCSV = pd.read_csv(databasePath + \"\\\\test_clean.csv\")\n",
    "    trainSetPath = databasePath + \"\\\\training_images\"\n",
    "    testSetPath = databasePath + \"\\\\testing_images\"\n",
    "\n",
    "    # Read the different classnames from the train.csv file\n",
    "    classnames = []\n",
    "    for label in trainSetCSV.iloc[:, 2]:\n",
    "        if label not in classnames:\n",
    "            classnames.append(label)\n",
    "            \n",
    "elif sourceToUse == 1:\n",
    "    databasePath = sourceImageFolder\n",
    "    trainSetPath = databasePath + \"\\\\training_images\"\n",
    "    testSetPath = databasePath + \"\\\\testing_images\"\n",
    "    classnames = [name for name in os.listdir(trainSetPath) if os.path.isdir(os.path.join(trainSetPath, name))]\n",
    "else:\n",
    "    raise ValueError('Pick a valid source folder to use.')\n",
    "    \n",
    "if not os.path.exists(databasePath):\n",
    "    raise ValueError('This database path does not exist: {0}'.format(databasePath))\n",
    "    \n",
    "if not os.path.exists(trainSetPath):\n",
    "    raise ValueError('This training set path does not exist: {0}'.format(trainSetPath))\n",
    "    \n",
    "if not os.path.exists(testSetPath):\n",
    "    raise ValueError('This test set path does not exist: {0}'.format(testSetPath))\n",
    " \n",
    "\n",
    "if USE_LAZY_IMAGE_LOADING:\n",
    "    print(\"Preparing images using lazy image loading...\\n\")\n",
    "else:\n",
    "    print(\"Preparing images using standard image loading...\\n\")\n",
    "\n",
    "loadErrors_train = 0\n",
    "loadErrors_test = 0\n",
    "augmentedTrainImages = 0\n",
    "augmentedTestImages = 0\n",
    "\n",
    "train_images_paths = []\n",
    "train_images = []\n",
    "train_classLabels = []\n",
    "for classLabel, classname in enumerate(classnames):\n",
    "    if sourceToUse == 0:\n",
    "        imgDir = trainSetPath + \"\\\\\" + str(classLabel)\n",
    "    else:\n",
    "        imgDir = trainSetPath + \"\\\\\" + classname\n",
    "    for i, imgName in enumerate(os.listdir(imgDir)):\n",
    "        imgPath = imgDir + \"\\\\\" + imgName\n",
    "        isAugmented = False\n",
    "        if \"_FLIPPEDLEFTRIGHT\" in imgPath or \"_ROTATED90\" in imgPath or \"_OVEREXPOSED\" in imgPath or \"_UNDEREXPOSED\" in imgPath or \"_BLURED\" in imgPath:\n",
    "            augmentedTrainImages += 1\n",
    "            isAugmented = True\n",
    "\n",
    "        if USE_TRAIN_AUGMENTATION or not isAugmented:\n",
    "            try: \n",
    "                img = Image.open(imgPath)\n",
    "                if img.size != (DIM, DIM):\n",
    "                    raise ValueError('Image is wrong size: ({0}, {1}) should be ({2}, {3})'.format(img.size[0], img.size[1], DIM, DIM))\n",
    "                if img.mode != \"RGB\":\n",
    "                    raise ValueError(\"Image is not RGB: '{0}' should be 'RGB'\".format(img.mode))\n",
    "                if not USE_LAZY_IMAGE_LOADING:\n",
    "                    train_images.append(img.copy())\n",
    "                else:\n",
    "                    train_images.append(imgPath)\n",
    "                train_images_paths.append(imgPath)\n",
    "                train_classLabels.append(classLabel)\n",
    "                img.close()\n",
    "            except:\n",
    "                loadErrors_train += 1\n",
    "        else:\n",
    "            augmentedTrainImages = 0\n",
    "\n",
    "\n",
    "test_images_paths = []\n",
    "test_images = []\n",
    "test_classLabels = []\n",
    "for classLabel, classname in enumerate(classnames):\n",
    "    if sourceToUse == 0:\n",
    "        imgDir = testSetPath + \"\\\\\" + str(classLabel)\n",
    "    else:\n",
    "        imgDir = testSetPath + \"\\\\\" + classname\n",
    "    for i, imgName in enumerate(os.listdir(imgDir)):\n",
    "        imgPath = imgDir + \"\\\\\" + imgName\n",
    "        isAugmented = False\n",
    "        if \"_FLIPPEDLEFTRIGHT\" in imgPath or \"_ROTATED90\" in imgPath or \"_OVEREXPOSED\" in imgPath or \"_UNDEREXPOSED\" in imgPath or \"_BLURED\" in imgPath:\n",
    "            augmentedTestImages += 1\n",
    "            isAugmented = True\n",
    "\n",
    "        if USE_TEST_AUGMENTATION or not isAugmented:\n",
    "            try: \n",
    "                img = Image.open(imgPath)\n",
    "                if img.size != (DIM, DIM):\n",
    "                    raise ValueError('Image is wrong size: ({0}, {1}) should be ({2}, {3})'.format(img.size[0], img.size[1], DIM, DIM))\n",
    "                if img.mode != \"RGB\":\n",
    "                    raise ValueError(\"Image is not RGB: '{0}' should be 'RGB'\".format(img.mode))\n",
    "                if not USE_LAZY_IMAGE_LOADING:\n",
    "                    test_images.append(img.copy())\n",
    "                else:\n",
    "                    test_images.append(imgPath)\n",
    "                test_images_paths.append(imgPath)\n",
    "                test_classLabels.append(classLabel)\n",
    "                img.close()\n",
    "            except:\n",
    "                loadErrors_test += 1\n",
    "        else:\n",
    "            augmentedTestImages = 0\n",
    "\n",
    "# Print data summary    \n",
    "print(\"Data summary:\\n\\nTraining data path: {0}\\nTesting data path: {1}\\n\\nNumber of classes: {2}\\nClass names: {3}\\n\\nUseable training images in total: {4}\\nUseable augmented training images in total: {5}\\n\\nUseable test images in total: {6}\\nUseable augmented test images in total: {7}\\n\\nTraining data errors: {8}\\nTesting data errors: {9}\".format(\n",
    "        trainSetPath,\n",
    "        testSetPath,\n",
    "        len(classnames), \n",
    "        classnames, \n",
    "        len(train_images),\n",
    "        augmentedTrainImages,\n",
    "        len(test_images),\n",
    "        augmentedTestImages,\n",
    "        loadErrors_train,\n",
    "        loadErrors_test))\n",
    "\n",
    "# Check for errors and warnings\n",
    "if len(train_images) < 1:\n",
    "    raise ValueError(\"\\nFailed to load any training images.\")\n",
    "\n",
    "if len(test_images) < 1:\n",
    "    raise ValueError(\"\\nFailed to load any testing images.\")\n",
    "\n",
    "if loadErrors_train > 0:\n",
    "    print(\"\\nWARNING: There seems to be {0} cases where a path did not point to a readable RGB image in the training_images folder. This is likely do to bugs in the scraper tool. Make sure all paths points to a readable RGB image of size ({1}, {2}) or ignore the errors and continue with only {3} training images.\".format(loadErrors_train, DIM, DIM, len(train_images)))\n",
    "else:\n",
    "    print(\"\\nSuccesfully loaded training images with no errors.\")\n",
    "\n",
    "if loadErrors_test > 0:\n",
    "    print(\"\\nWARNING: There seems to be {0} cases where a path did not point to a readable RGB image in the testing_images folder. This is likely do to bugs in the scraper tool. Make sure all paths points to a readable RGB image of size ({1}, {2}) or ignore the errors and continue with only {3} testing images.\".format(loadErrors_test, DIM, DIM, len(test_images)))\n",
    "else:\n",
    "    print(\"\\nSuccesfully loaded testing images with no errors.\") \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An efficient data generation scheme is crucial to leverage the full potential of your CPU (or GPU) during the training process so that the data generation process does not become a bottleneck. When the training and testing images has been loaded in the above, we can set up the dataloaders. For data loading, we implement a class that inherits the highly optimized Dataset type, and defines the data reading functions and data access functions as well as transforms that we will like to apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FoodDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, datasetType, transform):\n",
    "        \n",
    "        if datasetType == \"Training\":\n",
    "            self.images = train_images # With lazy image loading this will only be a list of paths\n",
    "            self.labels = train_classLabels\n",
    "        elif datasetType == \"Testing\":\n",
    "            self.images = test_images # With lazy image loading this will only be a list of paths\n",
    "            self.labels = test_classLabels\n",
    "        else:\n",
    "            raise ValueError(\"datasetType should be either 'Training' or 'Testing'.\")\n",
    "            \n",
    "        self.transform = transform;\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images);\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        if USE_LAZY_IMAGE_LOADING:\n",
    "            imageTemp = Image.open(image)\n",
    "            image = imageTemp.copy()\n",
    "            imageTemp.close()\n",
    "            \n",
    "        image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return {\"image\": image, \"label\": label};\n",
    "    \n",
    "    def getRandomIndexByLabel(self, labelx):\n",
    "        labelsList = [i for i, x in enumerate(self.labels) if x == labelx]\n",
    "        return random.sample(labelsList, 1)[0]\n",
    "    \n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available() and False\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(\"Using device: {0}\".format(device))\n",
    "\n",
    "# Parameters\n",
    "print(\"Using batch size: {0}\".format(BATCH_SIZE))\n",
    "params = {'batch_size': BATCH_SIZE,\n",
    "          'shuffle': True,\n",
    "          'num_workers': NUM_WORKERS}\n",
    "max_epochs = NUM_EPOCHS \n",
    "\n",
    "# Transformation\n",
    "#transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "transform=transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Data sets and loaders\n",
    "training_set = FoodDataset(datasetType=\"Training\", transform=transform)\n",
    "training_dataloader = torch.utils.data.DataLoader(training_set, **params)\n",
    "\n",
    "test_set = FoodDataset(datasetType=\"Testing\", transform=transform)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, **params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now easely get a single sample by index or use the dataloaders for batch training. A sample will consist of two objects: an image and a label like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the first sample from the training set dataloader\n",
    "sample = training_set[0]\n",
    "sample_image = sample[\"image\"]\n",
    "sample_label = sample[\"label\"]\n",
    "sample_label_name = classnames[sample_label]\n",
    "\n",
    "# Plot the image and print its class label and the name of its class label\n",
    "# When plotting an image we always swap the axis so that the image is displayed correctly\n",
    "print(\"The image looks like this when shown:\")\n",
    "sample_image = sample_image.transpose(0, 2) # Swap axis 0 and 2\n",
    "sample_image = sample_image.transpose(0, 1) # Swap axis 0 and 1\n",
    "plt.imshow(sample_image)\n",
    "plt.show()\n",
    "print(\"Its class label is '{0}' which is '{1}'\".format(sample_label, sample_label_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out a few images from each class to make sure everything is correctly set up and that the correct class names are associated with the correct images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numberOfImagesToShowPerClass = 5\n",
    "showAxis = True\n",
    "\n",
    "try:\n",
    "    print(\"Sampling images from training set...\")\n",
    "    for i in range(0, len(classnames)):\n",
    "        plt.figure(figsize=(12,30))\n",
    "        for k in range(0, numberOfImagesToShowPerClass):\n",
    "            j = training_set.getRandomIndexByLabel(i)\n",
    "            imgSample = training_set[j][\"image\"]\n",
    "            imgSample = imgSample.transpose(0, 2) # Swap axis 0 and 2\n",
    "            imgSample = imgSample.transpose(0, 1) # Swap axis 0 and 1\n",
    "            ax = plt.subplot(len(classnames), numberOfImagesToShowPerClass, k+1)\n",
    "            plt.tight_layout()\n",
    "            ax.set_title(\"{0}\".format(classnames[i]))\n",
    "            if not showAxis:\n",
    "                ax.axis('off')\n",
    "            plt.imshow(imgSample)\n",
    "\n",
    "    plt.show()\n",
    "except:\n",
    "    print(\"This failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Define a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Conv2d, BatchNorm2d, MaxPool2d, Dropout2d, Conv3d\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax, max_pool2d\n",
    "\n",
    "# hyperameters of the model\n",
    "channels = training_set[0][\"image\"].shape[0]\n",
    "height = training_set[0][\"image\"].shape[1]\n",
    "width = training_set[0][\"image\"].shape[2]\n",
    "print(\"Channels = {0}\\nHeight = {1}\\nWidth = {2}\".format(channels, height, width))\n",
    "\n",
    "num_filters_conv1 = 8\n",
    "kernel_size_conv1 = 8 # [height, width]\n",
    "stride_conv1 = 1 # [stride_height, stride_width]\n",
    "padding_conv1 = 0\n",
    "dropout1 = 0.5\n",
    "\n",
    "num_filters_conv2 = 16\n",
    "kernel_size_conv2 = 8 # [height, width]\n",
    "stride_conv2 = 2 # [stride_height, stride_width]\n",
    "padding_conv2 = 0\n",
    "dropout2 = 0.5\n",
    "\n",
    "num_filters_conv3 = 32\n",
    "kernel_size_conv3 = 8 # [height, width]\n",
    "stride_conv3 = 2 # [stride_height, stride_width]\n",
    "padding_conv3 = 0\n",
    "dropout3 = 0.5\n",
    "\n",
    "num_l1 = 1000\n",
    "num_l2 = 500\n",
    "\n",
    "def compute_conv_dim(dim_size, kernel_size, padding, stride):\n",
    "    return int((dim_size - kernel_size + 2 * padding) / stride + 1)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # First 2D convolutional layer\n",
    "        self.conv_1 = Conv2d(in_channels=channels, \n",
    "                             out_channels=num_filters_conv1, \n",
    "                             kernel_size=kernel_size_conv1, \n",
    "                             stride=stride_conv1)\n",
    "        self.conv1_out_height = compute_conv_dim(height, kernel_size_conv1, padding_conv1, stride_conv1)\n",
    "        self.conv1_out_width = compute_conv_dim(width, kernel_size_conv1, padding_conv1, stride_conv1)\n",
    "        #self.zeroPad_conv1 = nn.ZeroPad2d(padding_conv1)\n",
    "        self.dropout_1 = nn.Dropout2d(p=dropout1)\n",
    "        self.batchnorm_1 = nn.BatchNorm2d(num_filters_conv1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        \n",
    "        # Second 2D convolutional layer\n",
    "        self.conv_2 = Conv2d(in_channels=num_filters_conv1,\n",
    "                             out_channels=num_filters_conv2, \n",
    "                             kernel_size=kernel_size_conv2, \n",
    "                             stride=stride_conv2)\n",
    "        self.conv2_out_height = compute_conv_dim(self.conv1_out_height, kernel_size_conv2, padding_conv2, stride_conv2)\n",
    "        self.conv2_out_width = compute_conv_dim(self.conv1_out_width, kernel_size_conv2, padding_conv2, stride_conv2)\n",
    "        #self.zeroPad_conv2 = nn.ZeroPad2d(padding_conv2)\n",
    "        self.dropout_2 = nn.Dropout2d(p=dropout2)\n",
    "        self.batchnorm_2 = nn.BatchNorm2d(num_filters_conv2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        \n",
    "        # Third 2D convolutional layer\n",
    "        self.conv_3 = Conv2d(in_channels=num_filters_conv2,\n",
    "                             out_channels=num_filters_conv3, \n",
    "                             kernel_size=kernel_size_conv3, \n",
    "                             stride=stride_conv3)\n",
    "        self.conv3_out_height = compute_conv_dim(self.conv2_out_height, kernel_size_conv3, padding_conv3, stride_conv3)\n",
    "        self.conv3_out_width = compute_conv_dim(self.conv2_out_width, kernel_size_conv3, padding_conv3, stride_conv3)\n",
    "        #self.zeroPad_conv2 = nn.ZeroPad2d(padding_conv2)\n",
    "        self.dropout_3 = nn.Dropout2d(p=dropout3)\n",
    "        self.batchnorm_3 = nn.BatchNorm2d(num_filters_conv3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        \n",
    "        self.l1_in_features = 119072\n",
    "        \n",
    "        self.l_1 = Linear(in_features=self.l1_in_features, out_features=num_l1, bias=True)\n",
    "        self.l_2 = Linear(in_features=num_l1, out_features=num_l2, bias=True)\n",
    "        self.l_out = Linear(in_features=num_l2, out_features=num_classes, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = max_pool2d(x, kernel_size=5, padding=0, stride=1)\n",
    "        x = self.batchnorm_1(x)\n",
    "        #x = self.dropout_1(x)\n",
    "        x = relu(x)\n",
    "        \n",
    "        x = self.conv_2(x)\n",
    "        x = max_pool2d(x, kernel_size=5, padding=0, stride=1)\n",
    "        x = self.batchnorm_2(x)\n",
    "        #x = self.dropout_2(x)\n",
    "        x = relu(x)\n",
    "        \n",
    "        convOut = self.conv_3(x)\n",
    "        x = self.conv_3(x)\n",
    "        x = max_pool2d(x, kernel_size=5, padding=0, stride=1)\n",
    "        x = self.batchnorm_3(x)\n",
    "        #x = self.dropout_3(x)\n",
    "        x = relu(x)\n",
    "\n",
    "        x = x.view(x.size(0),-1)\n",
    "        \n",
    "        x = relu(self.l_1(x))\n",
    "        x = relu(self.l_2(x))\n",
    "        x = self.l_out(x)\n",
    "        #x = softmax(x, dim=1)\n",
    "        return x, convOut\n",
    "    \n",
    "\n",
    "net = Net(len(classnames))\n",
    "if use_cuda:\n",
    "    print('##converting network to cuda-enabled')\n",
    "    net.cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a loss function and an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001,  weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# NUM_EPOCHS # BATCHSIZE # Iterations\n",
    "#     3      #    32     #    9366\n",
    "#\n",
    "#\n",
    "\n",
    "iterations = 0\n",
    "secsPerIteration = 143 # Michaels computer\n",
    "\n",
    "print(\"Counting amount of work to do. Please wait...\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, data in enumerate(training_dataloader):\n",
    "        iterations += 1 \n",
    "        if i % 50 == 49:    # print every 10 mini-batches\n",
    "            print(\"{0} | {1} | {2}\".format(epoch+1, i+1, iterations))\n",
    "            \n",
    "#iterations = 9366\n",
    "        \n",
    "print(\"Total iterations to do: {0} (training will take approx. {1} hours on Michaels computer)\".format(iterations, (iterations*secsPerIteration)/3600))\n",
    "'''      \n",
    "print('Training. Please wait...')\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(training_dataloader):\n",
    "        #try:\n",
    "        # get the inputs\n",
    "        #print(data)\n",
    "        inputs, labels = data[\"image\"], data[\"label\"]\n",
    "\n",
    "        # wrap them in Variable\n",
    "        if use_cuda:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs, _ = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 10 == 9:    # print every 10 mini-batches\n",
    "            print('epoch: %2d/%2d, total iteration %5d/%5d | loss: %.3f' %\n",
    "                  (epoch + 1, NUM_EPOCHS, i + 1, iterations, running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "        #except:\n",
    "        #    print(\"This one failed.\")\n",
    "'''\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for data in test_dataloader:\n",
    "    images, labels = data[\"image\"], data[\"label\"]\n",
    "    if use_cuda:\n",
    "        outputs, _ = net(Variable(images.cuda()))\n",
    "    else:\n",
    "        outputs, _ = net(Variable(images))\n",
    "        \n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    if use_cuda:\n",
    "        correct += (predicted == labels.cuda()).sum()\n",
    "    else:\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the {} test images: {:4.2f} %'.format(\n",
    "    len(test_set), 100 * correct / total))\n",
    "\n",
    "print(\"(Random guessing would be {:4.2f} % on average)\\n\".format(100/len(classnames)))\n",
    "    \n",
    "class_total = list(0. for i in range(len(classnames)))\n",
    "class_correct = list(0. for i in range(len(classnames)))\n",
    "\n",
    "for data in test_dataloader:\n",
    "    images, labels = data[\"image\"], data[\"label\"]\n",
    "    if use_cuda:\n",
    "        outputs, _ = net(Variable(images.cuda()))\n",
    "    else:\n",
    "        outputs, _ = net(Variable(images))\n",
    "        \n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    if use_cuda:\n",
    "        c = (predicted == labels.cuda()).squeeze()\n",
    "    else:\n",
    "        c = (predicted == labels).squeeze()\n",
    "\n",
    "    try:\n",
    "        for i in range(len(c)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].cpu().numpy()\n",
    "            class_total[label] += 1\n",
    "    except:\n",
    "        print(\"c error ignored\\n\")\n",
    "\n",
    "for i in range(len(classnames)):\n",
    "    print('Accuracy of {0:10s}: {1} of {2} correct = {3:5.2f} %'.format(\n",
    "        classnames[i], int(class_correct[i]), int(class_total[i]), 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Get Saliency Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a random image we can use for testing saliency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_image = None\n",
    "sample_label = None\n",
    "sample_label_name = None\n",
    "label_vector = None\n",
    "\n",
    "for data in test_dataloader:\n",
    "    images, labels = data[\"image\"], data[\"label\"]\n",
    "    if use_cuda:\n",
    "        outputs, _ = net(Variable(images.cuda(), requires_grad=True))\n",
    "    else:\n",
    "        outputs, _ = net(Variable(images), requires_grad=True)\n",
    "        \n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    label_vector = outputs.data[0]\n",
    "    sample_image = images[0]\n",
    "    sample_label = predicted[0]\n",
    "    sample_label_name = classnames[sample_label]\n",
    "    \n",
    "    break\n",
    "    \n",
    "# Plot the image and print its class label and the name of its class label\n",
    "# When plotting an image we always swap the axis so that the image is displayed correctly\n",
    "print(\"The image looks like this when shown:\")\n",
    "sample_image = sample_image.transpose(0, 2) # Swap axis 0 and 2\n",
    "sample_image = sample_image.transpose(0, 1) # Swap axis 0 and 1\n",
    "plt.imshow(sample_image)\n",
    "plt.show()\n",
    "print(\"Its class label was predicted to be '{0}' which is '{1}' which may or may not be correct\".format(sample_label, sample_label_name))\n",
    "\n",
    "print(\"\\nThe label vector is\")\n",
    "print(label_vector)\n",
    "\n",
    "# Do backward pass\n",
    "backwardpassData = net.backward()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
